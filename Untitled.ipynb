{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xml.etree.ElementTree as et\n",
    "import os\n",
    "import regex\n",
    "import sys\n",
    "import dicttoxml\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/alexandrarottenkolber/Documents/02_Hertie_School/Master thesis/Master_Thesis_Hertie/data_analysis/01_data/Plenarprotokolle/\"\n",
    "\n",
    "# input directory\n",
    "RAW_XML = PATH + \"originals/\"\n",
    "\n",
    "# output directory\n",
    "RAW_TXT = PATH + \"output/\"\n",
    "\n",
    "if not os.path.exists(RAW_TXT):\n",
    "    os.makedirs(RAW_TXT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexandrarottenkolber/Documents/02_Hertie_School/Master thesis/Master_Thesis_Hertie/data_analysis/01_data/Plenarprotokolle/originals/.DS_Store\n",
      "/Users/alexandrarottenkolber/Documents/02_Hertie_School/Master thesis/Master_Thesis_Hertie/data_analysis/01_data/Plenarprotokolle/originals/pp01-data\n",
      "/Users/alexandrarottenkolber/Documents/02_Hertie_School/Master thesis/Master_Thesis_Hertie/data_analysis/01_data/Plenarprotokolle/originals/pp02-data\n",
      "/Users/alexandrarottenkolber/Documents/02_Hertie_School/Master thesis/Master_Thesis_Hertie/data_analysis/01_data/Plenarprotokolle/originals/pp03-data\n",
      "['/Users/alexandrarottenkolber/opt/anaconda3/envs/nlp3/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/Users/alexandrarottenkolber/Library/Jupyter/runtime/kernel-91e8e5fa-20ef-41ae-a22a-80c841a3ab15.json']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '03-data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d159390b11f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         if (\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melectoral_term_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         ):\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '03-data'"
     ]
    }
   ],
   "source": [
    "# Open every xml plenar file in every legislature period.\n",
    "for electoral_term_folder in sorted(os.listdir(RAW_XML)):\n",
    "    electoral_term_folder_path = os.path.join(RAW_XML, electoral_term_folder)\n",
    "\n",
    "    print(electoral_term_folder_path)\n",
    "    # Skip e.g. the .DS_Store file.\n",
    "    if not os.path.isdir(electoral_term_folder_path):\n",
    "        continue\n",
    "\n",
    "    if electoral_term_folder in [\"pp01-data\", \"pp02-data\"]:\n",
    "        continue\n",
    "\n",
    "    elif electoral_term_folder in [\n",
    "        \"pp03-data\",\n",
    "        \"pp04-data\",\n",
    "        \"pp05-data\",\n",
    "        \"pp06-data\",\n",
    "        \"pp07-data\",\n",
    "        \"pp08-data\",\n",
    "        \"pp09-data\",\n",
    "        \"pp10-data\",\n",
    "        \"pp11-data\",\n",
    "        \"pp12-data\",\n",
    "        \"pp13-data\",\n",
    "        \"pp14-data\",\n",
    "        \"pp15-data\",\n",
    "        \"pp16-data\",\n",
    "        \"pp17-data\",\n",
    "        \"pp18-data\",\n",
    "    ]:\n",
    "        begin_pattern_electoral_term = regex.compile(\n",
    "            r\"Beginn?:?\\s?(\\d){1,2}(\\s?[.,]\\s?(\\d){1,2})?\\s?Uhr\"\n",
    "        )\n",
    "\n",
    "        appendix_pattern_electoral_term = regex.compile(\n",
    "            r\"\\(Schlu(ß|ss)\\s?:?(.*?)\\d{1,2}\\D+(\\d{1,2})?(.*?)\\)?|\\(Ende der Sitzung: \\d{1,2}\\D+(\\d{1,2}) Uhr\\.?\\)\"  # noqa: E501\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"How did I come here?\")\n",
    "\n",
    "    if len(sys.argv) > 1:\n",
    "        print(sys.argv)\n",
    "        if (\n",
    "            str(int(regex.sub(\"pp\", \"\", electoral_term_folder)))\n",
    "            not in sys.argv\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "    print(electoral_term_folder)\n",
    "\n",
    "    for xml_file in sorted(os.listdir(electoral_term_folder_path)):\n",
    "        if \".xml\" in xml_file:\n",
    "            print(xml_file)\n",
    "            path = os.path.join(electoral_term_folder_path, xml_file)\n",
    "            tree = et.parse(path)\n",
    "\n",
    "            meta_data = {}\n",
    "\n",
    "            # Get the document number, the date of the session and the content.\n",
    "            meta_data[\"document_number\"] = tree.find(\"NR\").text\n",
    "            meta_data[\"date\"] = tree.find(\"DATUM\").text\n",
    "            text_corpus = tree.find(\"TEXT\").text\n",
    "\n",
    "            # Some files have issues which have to be handled mannualy\n",
    "            # like a duplicated text corpus or two sessions in one file.\n",
    "            if meta_data[\"document_number\"] == \"03/16\":\n",
    "                begin_pattern = begin_pattern_electoral_term\n",
    "                appendix_pattern = regex.compile(\n",
    "                    r\"\\(Schluß der Sitzung: 16\\.58 Uhr\\.\\)\"\n",
    "                )\n",
    "            elif meta_data[\"document_number\"] == \"04/69\":\n",
    "                begin_pattern = regex.compile(r\"Beginn: 9\\.01\")\n",
    "                appendix_pattern = appendix_pattern_electoral_term\n",
    "            elif meta_data[\"document_number\"] == \"04/176\":\n",
    "                begin_pattern = regex.compile(r\"Beginn: 16\\.02 Uhr\")\n",
    "                appendix_pattern = appendix_pattern_electoral_term\n",
    "            elif meta_data[\"document_number\"] == \"04/196\":\n",
    "                begin_pattern = begin_pattern_electoral_term\n",
    "                appendix_pattern = regex.compile(\n",
    "                    r\"Beifall.*?Schluß der Sitzung: 14\\.54 Uhr\\.\\)\"\n",
    "                )\n",
    "            elif meta_data[\"document_number\"] == \"05/76\":\n",
    "                begin_pattern = regex.compile(r\"\\(Beginn: 14\\.32 Uhr\\)\")\n",
    "                appendix_pattern = appendix_pattern_electoral_term\n",
    "            elif meta_data[\"document_number\"] == \"05/162\":\n",
    "                begin_pattern = regex.compile(r\"\\(Beginn: 21\\.13 Uhr\\.\\)\")\n",
    "                appendix_pattern = appendix_pattern_electoral_term\n",
    "            elif meta_data[\"document_number\"] == \"05/235\":\n",
    "                begin_pattern = begin_pattern_electoral_term\n",
    "                appendix_pattern = regex.compile(\n",
    "                    r\"\\(Schluß der Sitzung: 16\\.09 Uhr\\.\\)\"\n",
    "                )\n",
    "            elif meta_data[\"document_number\"] == \"07/145\":\n",
    "                # In this file the whole text is duplicated.\n",
    "                find_bundestag = list(\n",
    "                    regex.finditer(\"Deutscher Bundestag\\n\", text_corpus)\n",
    "                )\n",
    "                text_corpus = text_corpus[: find_bundestag[1].span()[0]]\n",
    "            elif meta_data[\"document_number\"] == \"07/243\":\n",
    "                begin_pattern = regex.compile(r\"Beginn: 9\\.00 Uhr(?=\\nPräsident)\")\n",
    "                appendix_pattern = appendix_pattern_electoral_term\n",
    "            elif meta_data[\"document_number\"] == \"08/7\":\n",
    "                begin_pattern = regex.compile(r\"Beginn: 9\\.00 Uhr(?=\\nPräsident)\")\n",
    "                appendix_pattern = appendix_pattern_electoral_term\n",
    "            elif meta_data[\"document_number\"] == \"08/146\":\n",
    "                begin_pattern = regex.compile(r\"Beginn: 8\\.00 Uhr\")\n",
    "                appendix_pattern = appendix_pattern_electoral_term\n",
    "            elif meta_data[\"document_number\"] == \"11/68\":\n",
    "                begin_pattern = begin_pattern_electoral_term\n",
    "                appendix_pattern = regex.compile(r\"\\(Schluß der Sitzung: 21\\. 07 Uhr\\)\")\n",
    "            elif meta_data[\"document_number\"] == \"11/155\":\n",
    "                begin_pattern = regex.compile(r\"Beginn: 9\\.00 Uhr(?=\\nVize)\")\n",
    "                appendix_pattern = appendix_pattern_electoral_term\n",
    "            elif meta_data[\"document_number\"] == \"14/17\":\n",
    "                begin_pattern = \"Beginn: 9.00 Uhr\"\n",
    "                appendix_pattern = (\n",
    "                    r\"Schluß: 12.06 Uhr\\)\\n\\nDruck: Bonner Universitäts-Buchdruckerei, 53113 Bonn\\n \"  # noqa: E501\n",
    "                    r\"53003 Bonn, Telefon: 02 28/3 82 08 40, Telefax: 02 28/3 82 08 44\\n\\n20\\n\\nBun\"\n",
    "                    r\"despräsident Dr. Roman Herzog\\n\\nDeutscher\"\n",
    "                )\n",
    "            elif meta_data[\"document_number\"] == \"14/21\":\n",
    "                begin_pattern = begin_pattern_electoral_term\n",
    "                appendix_pattern = r\"\\(Schluß: 22.18 Uhr\\)\\n\\nAdelheid Tröscher\\n\\n1594\"\n",
    "            elif meta_data[\"document_number\"] == \"14/192\":\n",
    "                begin_pattern = begin_pattern_electoral_term\n",
    "                appendix_pattern = regex.compile(\n",
    "                    r\"Vizepräsidentin Petra Bläss: Ich schließe die Aus-\\nsprache\\.(?=\\n\\nInter)\"\n",
    "                )\n",
    "            elif meta_data[\"document_number\"] == \"16/222\":\n",
    "                begin_pattern = begin_pattern_electoral_term\n",
    "                appendix_pattern = regex.compile(r\"\\(Schluss: 18\\.54 Uhr\\)\")\n",
    "            elif meta_data[\"document_number\"] == \"17/250\":\n",
    "                begin_pattern = regex.compile(r\"Beginn: 9.02 Uhr(?=\\nPräsident)\")\n",
    "                appendix_pattern = r\"\\(Schluss: 0.52 Uhr\\)\\n\\nIch\"\n",
    "            elif meta_data[\"document_number\"] == \"18/142\":\n",
    "                begin_pattern = begin_pattern_electoral_term\n",
    "                appendix_pattern = regex.compile(r\"\\(Schluss: 16 \\.36 Uhr\\)\")\n",
    "            elif meta_data[\"document_number\"] == \"18/237\":\n",
    "                begin_pattern = regex.compile(r\"Beginn: 9 \\.02 Uhr\")\n",
    "                appendix_pattern = appendix_pattern_electoral_term\n",
    "            elif meta_data[\"document_number\"] in [\n",
    "                \"03/97\",\n",
    "                \"04/66\",\n",
    "                \"04/87\",\n",
    "                \"04/112\",\n",
    "                \"05/47\",\n",
    "                \"05/232\",\n",
    "            ]:\n",
    "                # In these documents there are two sessions right after each\n",
    "                # other, and the following document is identical.\n",
    "                find_second = regex.search(\n",
    "                    \"(?<=\\n)\"\n",
    "                    + str(int(meta_data[\"document_number\"][3:]) + 1)\n",
    "                    + r\"\\. Sitzung(?=\\nBonn)\",\n",
    "                    text_corpus,\n",
    "                )\n",
    "                text_corpus = text_corpus[: find_second.span()[0]]\n",
    "            elif meta_data[\"document_number\"] in [\n",
    "                \"03/98\",\n",
    "                \"04/67\",\n",
    "                \"04/88\",\n",
    "                \"04/113\",\n",
    "                \"05/48\",\n",
    "                \"05/233\",\n",
    "            ]:\n",
    "                find_second = regex.search(\n",
    "                    \"(?<=\\n)\"\n",
    "                    + meta_data[\"document_number\"][3:]\n",
    "                    + r\"\\. Sitzung(?=\\nBonn)\",\n",
    "                    text_corpus,\n",
    "                )\n",
    "                text_corpus = text_corpus[find_second.span()[0] :]\n",
    "            else:\n",
    "                begin_pattern = begin_pattern_electoral_term\n",
    "                appendix_pattern = appendix_pattern_electoral_term\n",
    "\n",
    "            # Clean text corpus.\n",
    "            text_corpus = clean(text_corpus)\n",
    "\n",
    "            # Find the beginning pattern in plenar file.\n",
    "            find_beginnings = list(regex.finditer(begin_pattern, text_corpus))\n",
    "\n",
    "            # If found more than once or none, handle depending on period.\n",
    "            if len(find_beginnings) != 1:\n",
    "                continue\n",
    "\n",
    "            beginning_of_session = find_beginnings[0].span()[1]\n",
    "\n",
    "            toc = text_corpus[:beginning_of_session]\n",
    "            session_content = text_corpus[beginning_of_session:]\n",
    "\n",
    "            # At this point the document has a unique beginning. The spoken\n",
    "            # content begins after the matched phrase.\n",
    "\n",
    "            # Append \"END OF FILE\" to document text, otherwise pattern is\n",
    "            # not found, when appearing at the end of the file.\n",
    "            session_content += \"\\n\\nEND OF FILE\"\n",
    "\n",
    "            find_endings = list(regex.finditer(appendix_pattern, session_content))\n",
    "\n",
    "            if len(find_endings) != 1:\n",
    "                continue\n",
    "\n",
    "            # Appendix begins before the matched phrase.\n",
    "            end_of_session = find_endings[0].span()[0]\n",
    "\n",
    "            appendix = session_content[end_of_session:]\n",
    "            session_content = session_content[:end_of_session]\n",
    "\n",
    "            save_path = os.path.join(\n",
    "                RAW_TXT, electoral_term_folder, xml_file.replace(\".xml\", \"\")\n",
    "            )\n",
    "\n",
    "            # Save table of content, spoken content and appendix\n",
    "            # in separate folders.\n",
    "            if not os.path.exists(save_path):\n",
    "                os.makedirs(save_path)\n",
    "\n",
    "            with open(os.path.join(save_path, \"toc.txt\"), \"w\") as text_file:\n",
    "                text_file.write(toc)\n",
    "\n",
    "            with open(os.path.join(save_path, \"session_content.txt\"), \"w\") as text_file:\n",
    "                text_file.write(session_content)\n",
    "\n",
    "            with open(os.path.join(save_path, \"appendix.txt\"), \"w\") as text_file:\n",
    "                text_file.write(appendix)\n",
    "\n",
    "            with open(os.path.join(save_path, \"meta_data.xml\"), \"wb\") as result_file:\n",
    "                result_file.write(dicttoxml.dicttoxml(meta_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
