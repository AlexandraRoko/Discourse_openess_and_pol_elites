{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/alexandrarottenkolber/Documents/02_Hertie_School/Master thesis/Master_Thesis_Hertie/data_analysis/01_data/Wikipedia/output/\"\n",
    "MP_data= pd.read_csv(PATH + \"MP_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_for_special_chars(string): \n",
    "    string = re.sub('%C3%A4', 'ä', string)\n",
    "    string = re.sub('%C3%B6', 'ö', string)\n",
    "    string = re.sub('%C3%BC', 'ü', string)\n",
    "    string = re.sub('%E1%BA%9E', 'ß', string)\n",
    "    string = re.sub('%C3%9F', 'ß', string)\n",
    "    string = re.sub('%C3%A8', 'è', string)\n",
    "    string = re.sub('%C3%96', 'Ö', string)\n",
    "    string = re.sub('%C3%A9', 'é', string)\n",
    "    string = re.sub('%C4%B1', 'ı', string)\n",
    "    string = re.sub('%C4%9F', 'ğ', string)\n",
    "    string = re.sub('%C5%A1', 'š', string)\n",
    "    string = re.sub('%C4%87', 'ć', string)\n",
    "    string = re.sub('%C3%A7', 'ç', string)\n",
    "    string = re.sub('%C5%BB', 'Ż', string)\n",
    "    \n",
    "    \n",
    "    string = re.split(\"/\", string)[-1]\n",
    "    string = re.sub('_', ' ', string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MP_data[\"wikiurl_clean\"] = MP_data[\"wikiurl\"].map(lambda x: regex_for_special_chars(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ses = requests.Session()\n",
    "\n",
    "URL = \"https://de.wikipedia.org/w/api.php\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = list(MP_data[\"wikiurl_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that quieries the Wikipedia page history and creates dataframe for plotting a histogram \n",
    "\n",
    "# get date of today to specify start date\n",
    "now = dt.datetime.utcnow()\n",
    "\n",
    "#bring date in the right format\n",
    "time_today = now.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "def extract_revisions_to_df(title, number_of_revisions = 500, startdate = f\"{time_today}\"):\n",
    "    \"\"\"A function that quieries the Wiki page history and creates a list of dataframes dataframe for plotting a histogram \n",
    "\n",
    "    Arguments:\n",
    "        title: title of the Wikipedia Page\n",
    "        number_of_revisions: how many revisions will be extraced. Number must be between 0 and 500. Insert as integer.\n",
    "        startdate: offset in format 2020-04-06T14:32:32Z\n",
    "          \n",
    "    Returns: \n",
    "        - A dataframe with the number of revisions for a certain wikipedia page.\n",
    "        - The date of the earliest revision     \n",
    "    \"\"\"\n",
    "    \n",
    "    RVLIMIT = str(number_of_revisions)\n",
    "    RVSTART = str(startdate)\n",
    "    PARAMS = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"rvlimit\": f\"{RVLIMIT}\",\n",
    "        \"srprop\": \"size|wordcount|timestamp|snippet|titlesnippet\", \n",
    "        \"titles\": f\"{title}\",\n",
    "        #\"rvprop\": \"timestamp\",\n",
    "        \"rvslots\": \"main\", \n",
    "        \"rvdir\" : \"older\", \n",
    "        \"rvstart\": f\"{RVSTART}\"\n",
    "    }\n",
    "\n",
    "    R = Ses.get(url=URL, params=PARAMS)\n",
    "\n",
    "    history_data = R.json()\n",
    "    \n",
    "    pageid = list(history_data[\"query\"][\"pages\"].keys())[0]\n",
    "    \n",
    "    try: \n",
    "    \n",
    "        revision_df = pd.json_normalize(history_data[\"query\"][\"pages\"][f\"{pageid}\"][\"revisions\"])\n",
    "\n",
    "        revision_df[\"time_edited\"] = revision_df[\"timestamp\"].map(lambda x: dt.datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ'))\n",
    "        revision_df[\"date\"] = revision_df[\"timestamp\"].map(lambda x: x[:10]).map(lambda x: dt.datetime.strptime(x, '%Y-%m-%d'))\n",
    "        revision_df[\"title\"] = f\"{title}\"\n",
    "        earliest_revision = list(revision_df[\"timestamp\"])[-1]\n",
    "        last_revision = list(revision_df[\"timestamp\"])[0]\n",
    "        \n",
    "        date_string = list(revision_df[\"timestamp\"])[-1]\n",
    "        a = dt.datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%SZ')\n",
    "        b = a + dt.timedelta(seconds=60) #add five seconds for offset to not count the earliest revision twice\n",
    "        offset_string = b.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        \n",
    "        #print(f'''\\tCovering the time period from {earliest_revision} to {last_revision}.\\n''')\n",
    "        #If earlier revisions are of interest, use {date_string} as offset for the next query.\\n''')\n",
    "    \n",
    "        \n",
    "        return revision_df, offset_string\n",
    "        \n",
    "    except: \n",
    "        print(f'''=> Problem occured for {title}. Adding empty dataframe. \\n\\n''')\n",
    "        ls = pd.DataFrame([])\n",
    "        earliest_revision = np.nan\n",
    "        \n",
    "        return ls, earliest_revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function that qeries several pages at once and returns dataframe and a dictionary with the date of the first revision\n",
    "\n",
    "def combine_different_page_histories_to_one_df(list_of_page_titels, offsets_dic):\n",
    "    \"\"\"A function that quieries the Wiki page history and creates a list of dataframes dataframe for plotting a histogram \n",
    "\n",
    "    Arguments:\n",
    "        list_of_page_titels: a list of Wikipedia page titles\n",
    "        offsets_dic: a dictiornary with the dates where to start the query of revisions\n",
    "          \n",
    "    Returns: \n",
    "        - A merged data frame, containing the revision history for the wikipida pages mentioned in list_of_page_titels\n",
    "        - A dictionary containing the titele and date of the last revision which can be used to request ealier revisions\n",
    "    \"\"\"\n",
    "        \n",
    "    ls_of_dfs = []\n",
    "    offset_dic = {}\n",
    "    for title in list_of_page_titels: \n",
    "        #print(\"Processed: \\t\"+title)\n",
    "        temporal_df, earliest_revision = extract_revisions_to_df(title, startdate = offsets_dic[title])\n",
    "        ls_of_dfs.append(temporal_df)\n",
    "        offset_dic[title] = earliest_revision\n",
    "    \n",
    "    temp_merged_df = pd.concat(ls_of_dfs)\n",
    "    merged_df = temp_merged_df.reset_index()\n",
    "        \n",
    "    return merged_df, offset_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify start dates\n",
    "start_dates_dic = {}\n",
    "for title in titles: \n",
    "    start_dates_dic[title] = f\"{time_today}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2216"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "titles_rand = random.choices(titles, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Guido Westerwelle',\n",
       " 'Tobias Lindner (Politiker)',\n",
       " 'Manuel Sarrazin',\n",
       " 'Dorothea Szwed',\n",
       " 'Hubert Ulrich',\n",
       " 'Heinrich Zertik',\n",
       " 'Konstantin Kuhle',\n",
       " 'Karin Maag',\n",
       " 'Hans-Jochen Vogel',\n",
       " 'Katrin Kunert']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frist one done\n",
      "fifth one done\n",
      "tenth one done\n",
      "18th one done\n"
     ]
    }
   ],
   "source": [
    "# run request\n",
    "\n",
    "result_1, offset_dic_1 = combine_different_page_histories_to_one_df(titles, start_dates_dic)\n",
    "print(\"frist one done\")\n",
    "result_2, offset_dic_2 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_1)\n",
    "result_3, offset_dic_3 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_2)\n",
    "result_4, offset_dic_4 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_3)\n",
    "result_5, offset_dic_5 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_4)\n",
    "print(\"fifth one done\")\n",
    "result_6, offset_dic_6 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_5)\n",
    "result_7, offset_dic_7 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_6)\n",
    "result_8, offset_dic_8 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_7)\n",
    "result_9, offset_dic_9 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_8)\n",
    "result_10, offset_dic_10 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_9)\n",
    "result_11, offset_dic_11 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_10)\n",
    "print(\"tenth one done\")\n",
    "result_12, offset_dic_12 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_11)\n",
    "result_13, offset_dic_13 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_12)\n",
    "result_14, offset_dic_14 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_13)\n",
    "result_15, offset_dic_15 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_14)\n",
    "result_16, offset_dic_16 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_15)\n",
    "result_17, offset_dic_17 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_16)\n",
    "result_18, offset_dic_18 = combine_different_page_histories_to_one_df([titles[i] for i in range(len(titles))], offset_dic_17)\n",
    "print(\"18th one done\")\n",
    "\n",
    "# concatenate the resulting dataframes to one\n",
    "revisions_df = pd.concat([result_1, result_2, result_3, result_4, result_5, result_6, \n",
    "                          result_7, result_8, result_9, result_10, result_11, result_12, \n",
    "                          result_13, result_14, result_15, result_16, result_17, result_18]).reset_index()\n",
    "\n",
    "# reshape dataframe\n",
    "revisions_count = revisions_df.groupby([\"title\", \"date\"]).count().sort_values(by=['date']).reset_index()\n",
    "revisions_count = revisions_count.drop(columns= [\"level_0\", \"timestamp\", \"time_edited\"]).rename(columns={\"index\": \"no_of_revisions\"}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#revisions_df.to_csv(\"/Users/alexandrarottenkolber/Documents/02_Hertie_School/Master thesis/Master_Thesis_Hertie/data_analysis/01_data/Wikipedia/output/history_revisions_df_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisions_df = pd.read_csv(\"/Users/alexandrarottenkolber/Documents/02_Hertie_School/Master thesis/Master_Thesis_Hertie/data_analysis/01_data/Wikipedia/output/history_revisions_df_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-04-05T06:37:32Z'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revisions_df[\"timestamp\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strptime(revisions_df[\"timestamp\"][0], \"%Y-%m-%dT%H:%M:%SZ\").month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisions_df[\"year\"] = revisions_df[\"timestamp\"].map(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").year)\n",
    "revisions_df[\"month\"] = revisions_df[\"timestamp\"].map(lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisions_df_clean = revisions_df[[\"revid\",\"parentid\",\"user\",\"timestamp\",\"comment\",\"time_edited\",\"date\",\"title\",\"year\",\"month\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_for_special_chars_reversed(string): \n",
    "    string = re.sub('ä', '%C3%A4', string)\n",
    "    string = re.sub( 'ö', '%C3%B6', string)\n",
    "    string = re.sub( 'ü', '%C3%BC', string)\n",
    "    string = re.sub('ß','%E1%BA%9E', string)\n",
    "    string = re.sub('ß', '%C3%9F', string)\n",
    "    string = re.sub( 'è', '%C3%A8', string)\n",
    "    string = re.sub( 'Ö', '%C3%96', string)\n",
    "    string = re.sub('é', '%C3%A9', string)\n",
    "    string = re.sub( 'ı', '%C4%B1', string)\n",
    "    string = re.sub( 'ğ', '%C4%9F', string)\n",
    "    string = re.sub('š', '%C5%A1', string)\n",
    "    string = re.sub( 'ć', '%C4%87', string)\n",
    "    string = re.sub( 'ç', '%C3%A7', string)\n",
    "    string = re.sub( 'Ż', '%C5%BB', string)\n",
    "    \n",
    "    \n",
    "    string = re.split(\"/\", string)[-1]\n",
    "    string = re.sub( ' ', '_', string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['revid', 'parentid', 'user', 'timestamp', 'comment', 'time_edited',\n",
       "       'date', 'title', 'year', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revisions_df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revid</th>\n",
       "      <th>parentid</th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>comment</th>\n",
       "      <th>time_edited</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221797327</td>\n",
       "      <td>221792520</td>\n",
       "      <td>Nuuk</td>\n",
       "      <td>2022-04-05T06:37:32Z</td>\n",
       "      <td>/* Ehrendes Gedenken */ Dann auch nicht erwähn...</td>\n",
       "      <td>2022-04-05 06:37:32</td>\n",
       "      <td>2022-04-05 00:00:00</td>\n",
       "      <td>Willy Brandt</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221792520</td>\n",
       "      <td>220773568</td>\n",
       "      <td>Daniel Leon Sch.</td>\n",
       "      <td>2022-04-04T21:39:34Z</td>\n",
       "      <td>Die Information bezüglich der Namensgebung des...</td>\n",
       "      <td>2022-04-04 21:39:34</td>\n",
       "      <td>2022-04-04 00:00:00</td>\n",
       "      <td>Willy Brandt</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220773568</td>\n",
       "      <td>220740475</td>\n",
       "      <td>Redonebird</td>\n",
       "      <td>2022-03-04T11:26:03Z</td>\n",
       "      <td>Abschnittlink korrigiert</td>\n",
       "      <td>2022-03-04 11:26:03</td>\n",
       "      <td>2022-03-04 00:00:00</td>\n",
       "      <td>Willy Brandt</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220740475</td>\n",
       "      <td>220740267</td>\n",
       "      <td>Gloser</td>\n",
       "      <td>2022-03-03T06:52:24Z</td>\n",
       "      <td>Änderungen von [[Special:Contributions/Julia H...</td>\n",
       "      <td>2022-03-03 06:52:24</td>\n",
       "      <td>2022-03-03 00:00:00</td>\n",
       "      <td>Willy Brandt</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220740267</td>\n",
       "      <td>220697230</td>\n",
       "      <td>Julia Heitmann</td>\n",
       "      <td>2022-03-03T06:39:21Z</td>\n",
       "      <td>Ostpolitik</td>\n",
       "      <td>2022-03-03 06:39:21</td>\n",
       "      <td>2022-03-03 00:00:00</td>\n",
       "      <td>Willy Brandt</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       revid   parentid              user             timestamp  \\\n",
       "0  221797327  221792520              Nuuk  2022-04-05T06:37:32Z   \n",
       "1  221792520  220773568  Daniel Leon Sch.  2022-04-04T21:39:34Z   \n",
       "2  220773568  220740475        Redonebird  2022-03-04T11:26:03Z   \n",
       "3  220740475  220740267            Gloser  2022-03-03T06:52:24Z   \n",
       "4  220740267  220697230    Julia Heitmann  2022-03-03T06:39:21Z   \n",
       "\n",
       "                                             comment          time_edited  \\\n",
       "0  /* Ehrendes Gedenken */ Dann auch nicht erwähn...  2022-04-05 06:37:32   \n",
       "1  Die Information bezüglich der Namensgebung des...  2022-04-04 21:39:34   \n",
       "2                           Abschnittlink korrigiert  2022-03-04 11:26:03   \n",
       "3  Änderungen von [[Special:Contributions/Julia H...  2022-03-03 06:52:24   \n",
       "4                                         Ostpolitik  2022-03-03 06:39:21   \n",
       "\n",
       "                  date         title  year  month  \n",
       "0  2022-04-05 00:00:00  Willy Brandt  2022      4  \n",
       "1  2022-04-04 00:00:00  Willy Brandt  2022      4  \n",
       "2  2022-03-04 00:00:00  Willy Brandt  2022      3  \n",
       "3  2022-03-03 00:00:00  Willy Brandt  2022      3  \n",
       "4  2022-03-03 00:00:00  Willy Brandt  2022      3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revisions_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisions_df_clean[\"wikiurl_basename\"] = revisions_df_clean[\"title\"].map(lambda x: regex_for_special_chars_reversed(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202813688"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(list(revisions_df_clean[((revisions_df_clean[\"month\"] == 6) | (revisions_df_clean[\"month\"] == 7) | (revisions_df_clean[\"month\"] == 8)) & \n",
    "                   (revisions_df_clean[\"wikiurl_basename\"] == \"Guido_Westerwelle\") & \n",
    "                   (revisions_df_clean[\"year\"] == 2020)][\"revid\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012,\n",
       "       2011, 2010, 2009, 2008, 2007, 2006, 2005, 2004, 2003, 2002, 2001])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revisions_df_clean[\"year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201029756"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(list(revisions_df_clean[((revisions_df_clean[\"month\"] == 6) | (revisions_df_clean[\"month\"] == 7) | (revisions_df_clean[\"month\"] == 8)) & \n",
    "                        (revisions_df_clean[\"wikiurl_basename\"] == \"Guido_Westerwelle\") & \n",
    "                        (revisions_df_clean[\"year\"] == 2020)][\"revid\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_ids = []\n",
    "MP_basenames = []\n",
    "years = []\n",
    "for MP in list(revisions_df_clean[\"wikiurl_basename\"].unique()):\n",
    "    year_ls = sorted([2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005, 2004, 2003, 2002, 2001])\n",
    "    for year in year_ls: \n",
    "        if year in list(revisions_df_clean[\"year\"][revisions_df_clean[\"wikiurl_basename\"] == MP].unique()): \n",
    "            try:\n",
    "                revision_id = random.choice(list(revisions_df_clean[((revisions_df_clean[\"month\"] == 6) | (revisions_df_clean[\"month\"] == 7) | (revisions_df_clean[\"month\"] == 8)) & \n",
    "                                                               (revisions_df_clean[\"wikiurl_basename\"] == MP) & \n",
    "                                                               (revisions_df_clean[\"year\"] == year)][\"revid\"]))\n",
    "                wikiurl = revisions_df_clean[\"wikiurl_basename\"][revisions_df_clean[\"revid\"] == revision_id].unique()[0]\n",
    "\n",
    "                rev_ids.append(revision_id)\n",
    "                MP_basenames.append(wikiurl)\n",
    "                years.append(year) \n",
    "                \n",
    "            except IndexError: \n",
    "                #print(MP, year)\n",
    "                revision_id = random.choice(list(revisions_df_clean[(revisions_df_clean[\"wikiurl_basename\"] == MP) & \n",
    "                                                               (revisions_df_clean[\"year\"] == year)][\"revid\"]))\n",
    "                wikiurl = revisions_df_clean[\"wikiurl_basename\"][revisions_df_clean[\"revid\"] == revision_id].unique()[0]\n",
    "\n",
    "                rev_ids.append(revision_id)\n",
    "                MP_basenames.append(wikiurl)\n",
    "                years.append(year) \n",
    "        else: \n",
    "            year_ls_temp = list(revisions_df_clean[\"year\"][revisions_df_clean[\"wikiurl_basename\"] == MP].unique())\n",
    "            year_ls_temp.append(year)\n",
    "            year_ls_temp = sorted(year_ls_temp) \n",
    "            \n",
    "            idx = year_ls_temp.index(year)\n",
    "\n",
    "            if idx > 1: \n",
    "                year = year_ls_temp[idx-1]\n",
    "                \n",
    "                try:\n",
    "                    revision_id = random.choice(list(revisions_df_clean[((revisions_df_clean[\"month\"] == 6) | (revisions_df_clean[\"month\"] == 7) | (revisions_df_clean[\"month\"] == 8)) & \n",
    "                                                                   (revisions_df_clean[\"wikiurl_basename\"] == MP) & \n",
    "                                                                   (revisions_df_clean[\"year\"] == year)][\"revid\"]))\n",
    "                    wikiurl = revisions_df_clean[\"wikiurl_basename\"][revisions_df_clean[\"revid\"] == revision_id].unique()[0]\n",
    "\n",
    "                    rev_ids.append(revision_id)\n",
    "                    MP_basenames.append(wikiurl)\n",
    "                    years.append(year_ls_temp[idx-1+1]) \n",
    "                \n",
    "                except IndexError: \n",
    "                    revision_id = random.choice(list(revisions_df_clean[(revisions_df_clean[\"wikiurl_basename\"] == MP) & \n",
    "                                                                   (revisions_df_clean[\"year\"] == year)][\"revid\"]))\n",
    "                    wikiurl = revisions_df_clean[\"wikiurl_basename\"][revisions_df_clean[\"revid\"] == revision_id].unique()[0]\n",
    "\n",
    "                    rev_ids.append(revision_id)\n",
    "                    MP_basenames.append(wikiurl)\n",
    "                    years.append(year_ls_temp[idx-1+1]) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list(revisions_df_clean[\"year\"][revisions_df_clean[\"wikiurl_basename\"] == \"Tobias_Lindner_(Politiker)\"].unique())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "years = sorted([2022, 2021, 2018, 2017, 2016, 2014])\n",
    "years"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "years.append(2020)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "years = sorted(years) \n",
    "years"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "idx = years.index(2022)\n",
    "\n",
    "if idx > 1: \n",
    "    year = years[idx-1]\n",
    "    print(year)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "revisions_df_clean[((revisions_df_clean[\"month\"] == 5) | (revisions_df_clean[\"month\"] == 6) | (revisions_df_clean[\"month\"] == 7) | (revisions_df_clean[\"month\"] == 8) | (revisions_df_clean[\"month\"] == 9)) & \n",
    "                                                               (revisions_df_clean[\"wikiurl_basename\"] == \"Tobias_Lindner_(Politiker)\") & \n",
    "                                                               (revisions_df_clean[\"year\"] == 2016)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "list(revisions_df_clean[\"year\"][revisions_df_clean[\"wikiurl_basename\"] == \"Tobias_Lindner_(Politiker)\"].unique())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "revisions_df_clean[(revisions_df_clean[\"wikiurl_basename\"] == \"Tobias_Lindner_(Politiker)\") & (revisions_df_clean[\"year\"] == 2016)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31432, 31432, 31432)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rev_ids), len(MP_basenames), len(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"revision_id\"] = rev_ids\n",
    "data[\"wikiurl_basenames\"] = MP_basenames\n",
    "data[\"year\"] = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revision_id</th>\n",
       "      <th>wikiurl_basenames</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1225566</td>\n",
       "      <td>Willy_Brandt</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1225581</td>\n",
       "      <td>Willy_Brandt</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2032766</td>\n",
       "      <td>Willy_Brandt</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6179034</td>\n",
       "      <td>Willy_Brandt</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20416440</td>\n",
       "      <td>Willy_Brandt</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   revision_id wikiurl_basenames  year\n",
       "0      1225566      Willy_Brandt  2002\n",
       "1      1225581      Willy_Brandt  2003\n",
       "2      2032766      Willy_Brandt  2004\n",
       "3      6179034      Willy_Brandt  2005\n",
       "4     20416440      Willy_Brandt  2006"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2186"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"wikiurl_basenames\"].unique())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "revisions_df_clean[\"wikiurl_basename\"][revisions_df_clean[\"revid\"] == 9689776].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one representative revision per year\n",
    "data.to_csv(\"/Users/alexandrarottenkolber/Documents/02_Hertie_School/Master thesis/Master_Thesis_Hertie/data_analysis/01_data/Wikipedia/output/history_one_rep_revision_per_year_ids_names_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
